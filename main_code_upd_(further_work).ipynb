{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dona134/Metaphor-Classification-NLP/blob/main/main_code_upd_(further_work).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8066e65f",
      "metadata": {
        "id": "8066e65f"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dona134/Metaphor-Classification-NLP/blob/main/main_code_upd%20(further%20work).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d482b24d",
      "metadata": {
        "id": "d482b24d"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8f76a9ad",
      "metadata": {
        "id": "8f76a9ad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To suppress tokenizer parallelism warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "L1sKgvjiMzUW",
      "metadata": {
        "id": "L1sKgvjiMzUW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "i1iizLHHNL5S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1iizLHHNL5S",
        "outputId": "79eec70a-4609-481a-fc09-8dbc45aa407b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasketch in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.12/dist-packages (from datasketch) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasketch) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasketch\n",
        "from datasketch import MinHash, MinHashLSH\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9LALkqm5NQzf",
      "metadata": {
        "id": "9LALkqm5NQzf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Ns86sVOuNX1x",
      "metadata": {
        "id": "Ns86sVOuNX1x"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForTokenClassification, Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaTokenizerFast, XLMRobertaForTokenClassification, Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "GvO_GAOccDLC",
      "metadata": {
        "id": "GvO_GAOccDLC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from transformers import logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "69e43748",
      "metadata": {
        "id": "69e43748"
      },
      "outputs": [],
      "source": [
        "# plot confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3FfjgJW_OfJj",
      "metadata": {
        "id": "3FfjgJW_OfJj"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "26756c32",
      "metadata": {
        "id": "26756c32"
      },
      "outputs": [],
      "source": [
        "#!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Gez1EweUNz-L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "Gez1EweUNz-L",
        "outputId": "ad212c76-6b7a-47ea-9fe9-ecdcebfd5458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    document_name                                              words  \\\n",
              "0  a1e-fragment01  [Latest, corporate, unbundler, reveals, laid-b...   \n",
              "1  a1e-fragment01                                  [By, FRANK, KANE]   \n",
              "2  a1e-fragment01  [IT, SEEMS, that, Roland, Franklin, ,, the, la...   \n",
              "3  a1e-fragment01  [He, has, not, properly, investigated, the, ta...   \n",
              "4  a1e-fragment01  [The, 63-year-old, head, of, Pembridge, Invest...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0  [AJS, AJ0, NN1, VVZ, AJ0, NN1, PUN, NP0, NP0, ...   \n",
              "1                                [PRP, NP0, NP0-NN1]   \n",
              "2  [PNP, VVZ, CJT, NP0, NP0, PUN, AT0, AJS, NN1, ...   \n",
              "3  [PNP, VHZ, XX0, AV0, VVN, AT0, NN1, POS, NN1, ...   \n",
              "4  [AT0, AJ0, NN1, PRF, NP0, NN2, PUN, PRP, DTQ, ...   \n",
              "\n",
              "                                            met_type  \\\n",
              "0  [{'type': 'mrw/met', 'word_indices': [3]}, {'t...   \n",
              "1                                                 []   \n",
              "2  [{'type': 'mrw/met', 'word_indices': [16]}, {'...   \n",
              "3         [{'type': 'mrw/met', 'word_indices': [6]}]   \n",
              "4  [{'type': 'mrw/met', 'word_indices': [2]}, {'t...   \n",
              "\n",
              "                                                meta  \n",
              "0  [N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...  \n",
              "1                                    [N/A, N/A, N/A]  \n",
              "2  [N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...  \n",
              "3  [N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...  \n",
              "4  [N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65904292-db36-46a8-b4b7-bb2ee0578a3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_name</th>\n",
              "      <th>words</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>met_type</th>\n",
              "      <th>meta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[Latest, corporate, unbundler, reveals, laid-b...</td>\n",
              "      <td>[AJS, AJ0, NN1, VVZ, AJ0, NN1, PUN, NP0, NP0, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [3]}, {'t...</td>\n",
              "      <td>[N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[By, FRANK, KANE]</td>\n",
              "      <td>[PRP, NP0, NP0-NN1]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[N/A, N/A, N/A]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[IT, SEEMS, that, Roland, Franklin, ,, the, la...</td>\n",
              "      <td>[PNP, VVZ, CJT, NP0, NP0, PUN, AT0, AJS, NN1, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [16]}, {'...</td>\n",
              "      <td>[N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[He, has, not, properly, investigated, the, ta...</td>\n",
              "      <td>[PNP, VHZ, XX0, AV0, VVN, AT0, NN1, POS, NN1, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [6]}]</td>\n",
              "      <td>[N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[The, 63-year-old, head, of, Pembridge, Invest...</td>\n",
              "      <td>[AT0, AJ0, NN1, PRF, NP0, NN2, PUN, PRP, DTQ, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [2]}, {'t...</td>\n",
              "      <td>[N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, N/A, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65904292-db36-46a8-b4b7-bb2ee0578a3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65904292-db36-46a8-b4b7-bb2ee0578a3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65904292-db36-46a8-b4b7-bb2ee0578a3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7790b99d-c808-44e0-8a09-a148b6db0900\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7790b99d-c808-44e0-8a09-a148b6db0900')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7790b99d-c808-44e0-8a09-a148b6db0900 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16740,\n  \"fields\": [\n    {\n      \"column\": \"document_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 117,\n        \"samples\": [\n          \"a8m-fragment02\",\n          \"a1f-fragment09\",\n          \"acj-fragment01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"met_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"meta\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = pd.read_parquet(\"0000.parquet\")  # Let pandas choose the engine\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1962ebb5",
      "metadata": {
        "id": "1962ebb5"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns='meta')  # Drop unnecessary column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4db08d62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "4db08d62",
        "outputId": "ea12e893-2752-453a-c13a-473586cb8826"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    document_name                                              words  \\\n",
              "0  a1e-fragment01  [Latest, corporate, unbundler, reveals, laid-b...   \n",
              "1  a1e-fragment01                                  [By, FRANK, KANE]   \n",
              "2  a1e-fragment01  [IT, SEEMS, that, Roland, Franklin, ,, the, la...   \n",
              "3  a1e-fragment01  [He, has, not, properly, investigated, the, ta...   \n",
              "4  a1e-fragment01  [The, 63-year-old, head, of, Pembridge, Invest...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0  [AJS, AJ0, NN1, VVZ, AJ0, NN1, PUN, NP0, NP0, ...   \n",
              "1                                [PRP, NP0, NP0-NN1]   \n",
              "2  [PNP, VVZ, CJT, NP0, NP0, PUN, AT0, AJS, NN1, ...   \n",
              "3  [PNP, VHZ, XX0, AV0, VVN, AT0, NN1, POS, NN1, ...   \n",
              "4  [AT0, AJ0, NN1, PRF, NP0, NN2, PUN, PRP, DTQ, ...   \n",
              "\n",
              "                                            met_type  \n",
              "0  [{'type': 'mrw/met', 'word_indices': [3]}, {'t...  \n",
              "1                                                 []  \n",
              "2  [{'type': 'mrw/met', 'word_indices': [16]}, {'...  \n",
              "3         [{'type': 'mrw/met', 'word_indices': [6]}]  \n",
              "4  [{'type': 'mrw/met', 'word_indices': [2]}, {'t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc07a74d-7e60-4f09-9f1b-82431063d780\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_name</th>\n",
              "      <th>words</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>met_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[Latest, corporate, unbundler, reveals, laid-b...</td>\n",
              "      <td>[AJS, AJ0, NN1, VVZ, AJ0, NN1, PUN, NP0, NP0, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [3]}, {'t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[By, FRANK, KANE]</td>\n",
              "      <td>[PRP, NP0, NP0-NN1]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[IT, SEEMS, that, Roland, Franklin, ,, the, la...</td>\n",
              "      <td>[PNP, VVZ, CJT, NP0, NP0, PUN, AT0, AJS, NN1, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [16]}, {'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[He, has, not, properly, investigated, the, ta...</td>\n",
              "      <td>[PNP, VHZ, XX0, AV0, VVN, AT0, NN1, POS, NN1, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [6]}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[The, 63-year-old, head, of, Pembridge, Invest...</td>\n",
              "      <td>[AT0, AJ0, NN1, PRF, NP0, NN2, PUN, PRP, DTQ, ...</td>\n",
              "      <td>[{'type': 'mrw/met', 'word_indices': [2]}, {'t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc07a74d-7e60-4f09-9f1b-82431063d780')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc07a74d-7e60-4f09-9f1b-82431063d780 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc07a74d-7e60-4f09-9f1b-82431063d780');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-26994a8c-7ef2-4412-81dc-bcca7727a64a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26994a8c-7ef2-4412-81dc-bcca7727a64a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-26994a8c-7ef2-4412-81dc-bcca7727a64a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16740,\n  \"fields\": [\n    {\n      \"column\": \"document_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 117,\n        \"samples\": [\n          \"a8m-fragment02\",\n          \"a1f-fragment09\",\n          \"acj-fragment01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"met_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## filtering metaphor types"
      ],
      "metadata": {
        "id": "akmTjU_TXGJe"
      },
      "id": "akmTjU_TXGJe"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6de91d4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6de91d4f",
        "outputId": "b3eb4b28-70d6-4f5c-9753-83728dcd6600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mrw/met': 21887, 'mrw/met/WIDLII': 1825, 'mrw/met/PP': 1099, 'mrw/lit': 337, 'mrw/met/double': 211, 'mFlag/lex': 102, 'mFlag/phrase': 26, 'mrw/impl': 25, 'mrw/bridge': 22, 'mrw/met/OMM': 17, 'mrw/lit/WIDLII': 16, 'mFlag/morph': 12, 'mrw/met/M': 7, 'mFlag/lex/WIDLII': 5, 'mrw/met/ANIM': 2, 'mrw/impl/WIDLII': 1, 'mrw/met/UNKNOWN': 1, 'mFlag/phrase/WIDLII': 1}\n"
          ]
        }
      ],
      "source": [
        "# display the distribution of metaphor types (frequency of occurence in all the cells in met_type column)\n",
        "met_type_counts = {}\n",
        "for row in df['met_type'].dropna():\n",
        "    for t in row:\n",
        "        met_type = t['type']\n",
        "        if met_type in met_type_counts:\n",
        "            met_type_counts[met_type] += 1\n",
        "        else:\n",
        "            met_type_counts[met_type] = 1\n",
        "# Sort the dictionary by frequency in descending order\n",
        "sorted_met_type_counts = dict(sorted(met_type_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "print(sorted_met_type_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dd278417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd278417",
        "outputId": "4cd06c66-75cf-4815-a1bd-a9fac688f25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Metaphor Type: mrw/met ===\n",
            "\n",
            "Sentence: Latest corporate unbundler reveals laid-back approach : Roland Franklin , who is leading a 697m pound break-up bid for DRG , talks to Frank Kane\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([3], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([5], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([12], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([22], dtype=uint32)}]\n",
            "\n",
            "Sentence: IT SEEMS that Roland Franklin , the latest unbundler to appear in the UK , has made a fatal error in the preparation of his £697m break-up bid for stationery and packaging group DRG .\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([16], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([18], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([20], dtype=uint32)}]\n",
            "\n",
            "Sentence: He has not properly investigated the target 's dining facilities .\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([6], dtype=uint32)}]\n",
            "\n",
            "=== Metaphor Type: mrw/lit ===\n",
            "\n",
            "Sentence: The supposedly jokey answers are illustrated by photographs of people sleeping outside covered by copies of The Independent : they look like some of the hundreds of visitors who come to St Botolph ' s Crypt Centre for homeless people every day .\n",
            "met_type: [{'type': 'mrw/met/WIDLII', 'word_indices': array([5], dtype=uint32)}\n",
            " {'type': 'mFlag/lex', 'word_indices': array([21], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([22], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([25], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([27], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([28], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([29], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([30], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([31], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([32], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([34], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([35], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([36], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([38], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([39], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([40], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([41], dtype=uint32)}]\n",
            "\n",
            "Sentence: Nicholas was known as ‘ the uncle of Europe ’ for his success in marrying his beautiful but penniless daughters into the grander royal houses of Russia , Serbia and Italy .\n",
            "met_type: [{'type': 'mFlag/phrase', 'word_indices': array([2, 3], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([6], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([13], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([20], dtype=uint32)}]\n",
            "\n",
            "Sentence: The results are terse and sharply etched , like the best line drawings .\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([3], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([6], dtype=uint32)}\n",
            " {'type': 'mFlag/lex', 'word_indices': array([8], dtype=uint32)}\n",
            " {'type': 'mrw/lit', 'word_indices': array([11, 12], dtype=uint32)}]\n",
            "\n",
            "=== Metaphor Type: mrw/met/double ===\n",
            "\n",
            "Sentence: Montenegro 's young and go-ahead leadership , which came to power this year amid furious popular dissatisfaction with the ‘ old men in grey suits ’ , sponsored the gathering of Nicholas 's surviving relatives — the first ‘ royal reunion ’ organised by a Communist government .\n",
            "met_type: [{'type': 'mrw/met/PP', 'word_indices': array([2], dtype=uint32)}\n",
            " {'type': 'mrw/met/double', 'word_indices': array([8], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([9], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([10], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([11], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([13], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([14], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([17], dtype=uint32)}\n",
            " {'type': 'mrw/met/PP', 'word_indices': array([42], dtype=uint32)}]\n",
            "\n",
            "Sentence: AN INCOMING Labour government would turn large areas of Whitehall upside down — but the party 's policy review barely considers the implications of its plans for restructuring government departments .\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([1], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([5], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([10], dtype=uint32)}\n",
            " {'type': 'mrw/met/double', 'word_indices': array([19], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([24], dtype=uint32)}]\n",
            "\n",
            "Sentence: But the policy review nowhere considers the overall effect of the individual changes proposed , or how they might be co-ordinated .\n",
            "met_type: [{'type': 'mrw/met/WIDLII', 'word_indices': array([4], dtype=uint32)}\n",
            " {'type': 'mrw/met/double', 'word_indices': array([5], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([20], dtype=uint32)}]\n",
            "\n",
            "=== Metaphor Type: mrw/met/PP ===\n",
            "\n",
            "Sentence: It does not matter whether or not DRG makes sellotape or Basildon Bond — it 's of no consequence to anybody if somebody else makes them . ’\n",
            "met_type: [{'type': 'mrw/met/PP', 'word_indices': array([6], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([17], dtype=uint32)}]\n",
            "\n",
            "Sentence: Labour hopes to transform the situation by increasing the number of A- levels to five for the brighter youngsters and providing grants for four-year training courses ( two years in a Further Education college followed by two with an employer ) for the rest .\n",
            "met_type: [{'type': 'mrw/met/PP', 'word_indices': array([1], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([5], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([12], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([13], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([17], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([25], dtype=uint32)}\n",
            " {'type': 'mrw/met/WIDLII', 'word_indices': array([31], dtype=uint32)}\n",
            " {'type': 'mrw/met', 'word_indices': array([34], dtype=uint32)}\n",
            " {'type': 'mrw/met/WIDLII', 'word_indices': array([37], dtype=uint32)}]\n",
            "\n",
            "Sentence: ‘ What do independent experts say about our 10 extra pages ? ’ asks the advertisement .\n",
            "met_type: [{'type': 'mrw/met', 'word_indices': array([6], dtype=uint32)}\n",
            " {'type': 'mrw/met/PP', 'word_indices': array([13], dtype=uint32)}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Show full sentences without column truncation\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "met_types = [\n",
        "    'mrw/met', 'mrw/lit','mrw/met/double','mrw/met/PP'\n",
        "]\n",
        "\n",
        "for mtype in met_types:\n",
        "    print(f\"\\n=== Metaphor Type: {mtype} ===\")\n",
        "\n",
        "    # Find rows where met_type contains at least one dict with the matching type\n",
        "    mask = df['met_type'].apply(\n",
        "        lambda arr: any(\n",
        "            isinstance(d, dict) and d.get('type') == mtype\n",
        "            for d in (arr.tolist() if isinstance(arr, np.ndarray) else arr)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    subset = df[mask][['words', 'met_type']].head(3)\n",
        "\n",
        "    if subset.empty:\n",
        "        print(\"No examples found.\")\n",
        "        continue\n",
        "\n",
        "    for _, row in subset.iterrows():\n",
        "        sentence = \" \".join(row['words'])\n",
        "        print(\"\\nSentence:\", sentence)\n",
        "        print(\"met_type:\", row['met_type'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71ed3e6",
      "metadata": {
        "id": "c71ed3e6"
      },
      "source": [
        "1️⃣ mrw/met (Indirect Metaphor)\n",
        "\n",
        "Description:\n",
        "\n",
        "Words used metaphorically by extending a more basic, concrete meaning into a new, abstract domain.\n",
        "\n",
        "Often contrast between a literal/basic meaning and a contextual/figurative meaning.\n",
        "\n",
        "Classic cross-domain metaphor.\n",
        "\n",
        "Examples:\n",
        "\n",
        "“Roland Franklin … leading a 697m pound break-up bid for DRG.” → “break-up” normally refers to separation of things, here applied to corporate restructuring.\n",
        "\n",
        "“He has made a fatal error in the preparation of his bid.” → “fatal” usually refers to death, here applied metaphorically to business failure.\n",
        "\n",
        "2️⃣ mrw/lit (Direct / Literal Comparison Metaphor)\n",
        "\n",
        "Description:\n",
        "\n",
        "Metaphors expressed via explicit comparison, often marked by words like like or as.\n",
        "\n",
        "The word itself is used literally but in a metaphorical comparison.\n",
        "\n",
        "Examples:\n",
        "\n",
        "“They look like some of the hundreds of visitors who come to St Botolph’s Crypt Centre.” → “like” signals a direct comparison.\n",
        "\n",
        "“The results are terse and sharply etched, like the best line drawings.” → “line drawings” is literal, comparison makes it a metaphor.\n",
        "\n",
        "3️⃣ mrw/met/double (Double Metaphor / Multiple Readings)\n",
        "\n",
        "Description:\n",
        "\n",
        "Tokens that convey more than one metaphorical meaning at the same time.\n",
        "\n",
        "Often a combination of indirect and figurative meaning, or overlapping metaphorical interpretations.\n",
        "\n",
        "Examples:\n",
        "\n",
        "“…turn large areas of Whitehall upside down …” → literal spatial sense + figurative meaning of restructuring.\n",
        "\n",
        "“Montenegro's go-ahead leadership …” → “go-ahead” can mean energetic and forward-thinking simultaneously.\n",
        "\n",
        "4️⃣ mrw/met/PP (Possible Personification)\n",
        "\n",
        "Description:\n",
        "\n",
        "Abstract or non-human entities performing human actions, often personification.\n",
        "\n",
        "Usually marked when annotators think human-like attributes are applied.\n",
        "\n",
        "Examples:\n",
        "\n",
        "“…it’s of no consequence to anybody if somebody else makes them.” → “it” acts as if it can “matter”\n",
        "\n",
        "“…the advertisement asks…” → ad behaves like a person.\n",
        "\n",
        "“…Labour hopes to transform the situation …” → abstract entity “Labour” acting intentionally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde1f912",
      "metadata": {
        "id": "bde1f912"
      },
      "source": [
        "The dataset description can be found here: http://www.vismet.org/metcor/manual/index.php"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b622dbe6",
      "metadata": {
        "id": "b622dbe6"
      },
      "source": [
        "# RoBERTa token classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a66b04",
      "metadata": {
        "id": "b6a66b04"
      },
      "source": [
        "## Preprocessing the data for the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "950da495",
      "metadata": {
        "id": "950da495"
      },
      "outputs": [],
      "source": [
        "df_filtered=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0eca73d6",
      "metadata": {
        "id": "0eca73d6"
      },
      "outputs": [],
      "source": [
        "target_types = {'mrw/met', 'mrw/lit', 'mrw/met/double', 'mrw/met/PP'}\n",
        "\n",
        "df_filtered = df_filtered[df_filtered[\"met_type\"].apply(\n",
        "    lambda items: any(item[\"type\"] in target_types for item in items)\n",
        ")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1ca35161",
      "metadata": {
        "id": "1ca35161"
      },
      "outputs": [],
      "source": [
        "met_map = {\n",
        "    'mrw/met': 'Indirect',\n",
        "    'mrw/lit': 'Direct',\n",
        "    'mrw/met/double': 'Double',\n",
        "    'mrw/met/PP': 'Personification'\n",
        "}\n",
        "\n",
        "met_types_for_label = set(met_map)\n",
        "\n",
        "def simple_pos_map(pos):\n",
        "    return (\n",
        "        \"verb\" if pos.startswith(\"V\") else\n",
        "        \"noun\" if pos.startswith(\"N\") else\n",
        "        \"adj\"  if pos.startswith(\"AJ\") else\n",
        "        \"adv\"  if pos.startswith(\"AV\") else\n",
        "        \"nan\"\n",
        "    )\n",
        "\n",
        "def process_row(row):\n",
        "    length = len(row[\"pos_tags\"])\n",
        "\n",
        "    # init outputs\n",
        "    metaphor_type = [\"literal\"] * length\n",
        "    labels = [0] * length\n",
        "\n",
        "    # fill both metaphor types + labels\n",
        "    for item in row[\"met_type\"]:\n",
        "        t = item[\"type\"]\n",
        "        mapped = met_map.get(t, \"literal\")\n",
        "        is_met = t in met_types_for_label\n",
        "\n",
        "        for idx in item[\"word_indices\"]:\n",
        "            metaphor_type[idx] = mapped\n",
        "            if is_met:\n",
        "                labels[idx] = 1\n",
        "\n",
        "    # pos tags for all tokens\n",
        "    pos = [\n",
        "        simple_pos_map(tag)\n",
        "        for tag in row[\"pos_tags\"]\n",
        "    ]\n",
        "\n",
        "    return labels, metaphor_type, pos\n",
        "\n",
        "\n",
        "# ---- APPLY ----\n",
        "df_filtered[[\"labels\", \"metaphor_type\", \"pos\"]] = (\n",
        "    df_filtered.apply(lambda row: pd.Series(process_row(row)), axis=1)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e9a50ad2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9a50ad2",
        "outputId": "6812dfba-230e-4445-cfee-d9d436417176"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    document_name  \\\n",
              "0  a1e-fragment01   \n",
              "2  a1e-fragment01   \n",
              "3  a1e-fragment01   \n",
              "4  a1e-fragment01   \n",
              "5  a1e-fragment01   \n",
              "\n",
              "                                                                                                                                                                                                                                                                           words  \\\n",
              "0                                                                                                     [Latest, corporate, unbundler, reveals, laid-back, approach, :, Roland, Franklin, ,, who, is, leading, a, 697m, pound, break-up, bid, for, DRG, ,, talks, to, Frank, Kane]   \n",
              "2                                                    [IT, SEEMS, that, Roland, Franklin, ,, the, latest, unbundler, to, appear, in, the, UK, ,, has, made, a, fatal, error, in, the, preparation, of, his, £697m, break-up, bid, for, stationery, and, packaging, group, DRG, .]   \n",
              "3                                                                                                                                                                                                 [He, has, not, properly, investigated, the, target, 's, dining, facilities, .]   \n",
              "4  [The, 63-year-old, head, of, Pembridge, Investments, ,, through, which, the, bid, is, being, mounted, says, ,, ‘, rule, number, one, in, this, business, is, :, the, more, luxurious, the, luncheon, rooms, at, headquarters, ,, the, more, inefficient, the, business, ’, .]   \n",
              "5                                                                                                     [If, he, had, taken, his, own, rule, seriously, ,, he, would, have, found, out, that, DRG, has, a, very, modest, self-service, canteen, at, its, Bristol, head, office, .]   \n",
              "\n",
              "                                                                                                                        labels  \\\n",
              "0                                                  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "2                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "3                                                                                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
              "4  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5                                         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                             metaphor_type  \\\n",
              "0                                                                                                                                                    [literal, literal, literal, Indirect, literal, Indirect, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal]   \n",
              "2                                                           [literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, Indirect, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal]   \n",
              "3                                                                                                                                                                                                                                                                                     [literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal]   \n",
              "4  [literal, literal, Indirect, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, Indirect, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal]   \n",
              "5                                                                                                                          [literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, Indirect, literal, literal]   \n",
              "\n",
              "                                                                                                                                                                                                                             pos  \n",
              "0                                                                                   [adj, adj, noun, verb, adj, noun, nan, noun, noun, nan, nan, verb, verb, nan, noun, noun, noun, noun, nan, noun, nan, noun, nan, noun, noun]  \n",
              "2                               [nan, verb, nan, noun, noun, nan, nan, adj, noun, nan, verb, nan, nan, noun, nan, verb, verb, nan, adj, noun, nan, nan, noun, nan, nan, noun, noun, noun, nan, noun, nan, noun, noun, noun, nan]  \n",
              "3                                                                                                                                                                   [nan, verb, nan, adv, verb, nan, noun, nan, noun, noun, nan]  \n",
              "4  [nan, adj, noun, nan, noun, noun, nan, nan, nan, nan, noun, verb, verb, verb, verb, nan, nan, noun, noun, nan, nan, nan, noun, verb, nan, nan, adv, adj, nan, noun, noun, nan, noun, nan, nan, adv, adj, nan, noun, nan, nan]  \n",
              "5                                                                        [nan, nan, verb, verb, nan, nan, noun, adv, nan, nan, verb, verb, verb, adv, nan, noun, verb, nan, adv, adj, adj, noun, nan, nan, noun, adj, noun, nan]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee783b55-0832-49c3-984e-da7e073def07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_name</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "      <th>metaphor_type</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[Latest, corporate, unbundler, reveals, laid-back, approach, :, Roland, Franklin, ,, who, is, leading, a, 697m, pound, break-up, bid, for, DRG, ,, talks, to, Frank, Kane]</td>\n",
              "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[literal, literal, literal, Indirect, literal, Indirect, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal]</td>\n",
              "      <td>[adj, adj, noun, verb, adj, noun, nan, noun, noun, nan, nan, verb, verb, nan, noun, noun, noun, noun, nan, noun, nan, noun, nan, noun, noun]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[IT, SEEMS, that, Roland, Franklin, ,, the, latest, unbundler, to, appear, in, the, UK, ,, has, made, a, fatal, error, in, the, preparation, of, his, £697m, break-up, bid, for, stationery, and, packaging, group, DRG, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, Indirect, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal]</td>\n",
              "      <td>[nan, verb, nan, noun, noun, nan, nan, adj, noun, nan, verb, nan, nan, noun, nan, verb, verb, nan, adj, noun, nan, nan, noun, nan, nan, noun, noun, noun, nan, noun, nan, noun, noun, noun, nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[He, has, not, properly, investigated, the, target, 's, dining, facilities, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal]</td>\n",
              "      <td>[nan, verb, nan, adv, verb, nan, noun, nan, noun, noun, nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[The, 63-year-old, head, of, Pembridge, Investments, ,, through, which, the, bid, is, being, mounted, says, ,, ‘, rule, number, one, in, this, business, is, :, the, more, luxurious, the, luncheon, rooms, at, headquarters, ,, the, more, inefficient, the, business, ’, .]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[literal, literal, Indirect, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, Indirect, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal]</td>\n",
              "      <td>[nan, adj, noun, nan, noun, noun, nan, nan, nan, nan, noun, verb, verb, verb, verb, nan, nan, noun, noun, nan, nan, nan, noun, verb, nan, nan, adv, adj, nan, noun, noun, nan, noun, nan, nan, adv, adj, nan, noun, nan, nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a1e-fragment01</td>\n",
              "      <td>[If, he, had, taken, his, own, rule, seriously, ,, he, would, have, found, out, that, DRG, has, a, very, modest, self-service, canteen, at, its, Bristol, head, office, .]</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[literal, literal, literal, Indirect, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, literal, Indirect, literal, literal, literal, literal, literal, Indirect, literal, literal]</td>\n",
              "      <td>[nan, nan, verb, verb, nan, nan, noun, adv, nan, nan, verb, verb, verb, adv, nan, noun, verb, nan, adv, adj, adj, noun, nan, nan, noun, adj, noun, nan]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee783b55-0832-49c3-984e-da7e073def07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee783b55-0832-49c3-984e-da7e073def07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee783b55-0832-49c3-984e-da7e073def07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c521108b-ab22-43d3-9e34-d1a87d066187\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c521108b-ab22-43d3-9e34-d1a87d066187')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c521108b-ab22-43d3-9e34-d1a87d066187 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered",
              "summary": "{\n  \"name\": \"df_filtered\",\n  \"rows\": 7850,\n  \"fields\": [\n    {\n      \"column\": \"document_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 117,\n        \"samples\": [\n          \"a8m-fragment02\",\n          \"a1f-fragment09\",\n          \"acj-fragment01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metaphor_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#drop columns 'met_type' and 'pos_tags' as they are no longer needed\n",
        "df_filtered = df_filtered.drop(columns=['met_type', 'pos_tags'])\n",
        "df_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "73c00153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73c00153",
        "outputId": "6422b501-6aa0-4995-c14d-b3b8f4448ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sentence length: 21.57 tokens\n",
            "Max sentence length: 127 tokens\n",
            "Min sentence length: 1 tokens\n"
          ]
        }
      ],
      "source": [
        "# average sentence length\n",
        "print(f\"Average sentence length: {df_filtered['words'].apply(len).mean():.2f} tokens\")\n",
        "# max and min\n",
        "print(f\"Max sentence length: {df_filtered['words'].apply(len).max()} tokens\")\n",
        "print(f\"Min sentence length: {df_filtered['words'].apply(len).min()} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "I6V2Y5oq7C2D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6V2Y5oq7C2D",
        "outputId": "72a9caf4-dada-4b56-8397-45240ff6c744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7825, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# keep sentences with at least 3 words\n",
        "df_filtered = df_filtered[df_filtered['words'].apply(len) > 2]\n",
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "eWxD-N5NqJaj",
      "metadata": {
        "id": "eWxD-N5NqJaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "002d6cd6-d3c6-44fd-ab3e-ed0a529fb44b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mimport_protobuf_decode_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, sp_model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoad\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromSerializedProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_LoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Not found: \"None\": No such file or directory Error #2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1804542379.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Initialize tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m tokenizer = XLMRobertaTokenizerFast.from_pretrained(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"xlm-roberta-base\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfrom_slow\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_tokenizer_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslow_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m             slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\n\u001b[0m\u001b[1;32m   2152\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m   2375\u001b[0m                 \u001b[0;34m\"Unable to load vocabulary from file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m                 \u001b[0;34m\"Please check that the provided vocabulary is accessible and not corrupted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted."
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizerFast\n",
        "# Initialize tokenizer\n",
        "\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    add_prefix_space=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff724db5"
      },
      "source": [
        "class MetaphorSentenceDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=64):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Encodings for Trainer\n",
        "        self.encodings = {\n",
        "            'input_ids': [],\n",
        "            'attention_mask': [],\n",
        "            'labels': []\n",
        "        }\n",
        "\n",
        "        # Separate lists to use later for evaluation\n",
        "        self.word_ids_list = []\n",
        "        self.simple_pos_list = []\n",
        "        self.metaphor_type_list = [] # Added for storing aligned metaphor types\n",
        "\n",
        "        # POS mapping (simplified)\n",
        "        self.simple_pos_mapping = {'nan': 'na', 'verb': 'verb', 'noun': 'noun', 'adv': 'adv',\n",
        "                                   'adj': 'adj', 'SPECIAL': 'SPECIAL',\n",
        "                                   'SUBWORD': 'SUBWORD', 'UNKNOWN_POS': 'UNKNOWN_POS', 'PAD': 'PAD'}\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            words = [str(w) for w in row[\"words\"]]\n",
        "            labels = [int(l) for l in row[\"labels\"]]\n",
        "            simple_pos = [str(p) for p in row[\"pos\"]] # These are the actual POS tags\n",
        "            metaphor_types_orig = [str(m) for m in row[\"metaphor_type\"]] # Get original metaphor types\n",
        "\n",
        "            encoding = self.tokenizer(\n",
        "                words,\n",
        "                is_split_into_words=True,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=self.max_len,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            word_ids = encoding.word_ids(batch_index=0)\n",
        "            aligned_labels = []\n",
        "            aligned_pos = []\n",
        "            aligned_metaphor_type = [] # New list for metaphor types\n",
        "\n",
        "            prev_word_id = None\n",
        "            for i, word_id in enumerate(word_ids):\n",
        "                if word_id is None:\n",
        "                    aligned_labels.append(-100)\n",
        "                    aligned_pos.append(\"SPECIAL\")\n",
        "                    aligned_metaphor_type.append(\"SPECIAL\") # Align metaphor type\n",
        "                elif word_id != prev_word_id:\n",
        "                    aligned_labels.append(labels[word_id])\n",
        "                    aligned_pos.append(simple_pos[word_id])\n",
        "                    aligned_metaphor_type.append(metaphor_types_orig[word_id]) # Align metaphor type\n",
        "                    prev_word_id = word_id\n",
        "                else:\n",
        "                    aligned_labels.append(-100)\n",
        "                    aligned_pos.append(\"SUBWORD\")\n",
        "                    aligned_metaphor_type.append(\"SUBWORD\") # Align metaphor type\n",
        "\n",
        "            # Convert to tensors\n",
        "            self.encodings['input_ids'].append(encoding['input_ids'].squeeze(0))\n",
        "            self.encodings['attention_mask'].append(encoding['attention_mask'].squeeze(0))\n",
        "            self.encodings['labels'].append(torch.tensor(aligned_labels, dtype=torch.long))\n",
        "\n",
        "            # Save for evaluation\n",
        "            self.word_ids_list.append(word_ids)\n",
        "            self.simple_pos_list.append(aligned_pos)\n",
        "            self.metaphor_type_list.append(aligned_metaphor_type) # Save aligned metaphor types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Support both single index and batch (list/ndarray) index\n",
        "        if isinstance(idx, (int, np.integer)):\n",
        "            return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "        # If idx is a list, tuple, or np.ndarray, return a batch\n",
        "        if isinstance(idx, (list, tuple, np.ndarray)):\n",
        "            return {key: [self.encodings[key][i] for i in idx] for key in self.encodings}\n",
        "        raise TypeError(f\"Invalid index type: {type(idx)}\")"
      ],
      "id": "ff724db5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cz10QHV5SUjW",
      "metadata": {
        "id": "cz10QHV5SUjW"
      },
      "outputs": [],
      "source": [
        "# # Example alignment:\n",
        "# Original words: [\"running\", \"quickly\", \"home\"]\n",
        "# Original labels: [1, 0, 0]  # \"running\" is metaphorical\n",
        "\n",
        "# # After tokenization:\n",
        "# Tokens: [\"<s>\", \"running\", \"quickly\", \"home\", \"</s>\", \"<pad>\", \"<pad>\"]\n",
        "# Labels: [-100, 1, 0, 0, -100, -100, -100]\n",
        "# #        ^     ^  ^  ^   ^     ^      ^\n",
        "# #        |     |  |  |   |     |      └─ padding\n",
        "# #        |     |  |  |   |     └─ padding\n",
        "# #        |     |  |  |   └─ end token (ignore)\n",
        "# #        |     |  |  └─ \"home\" (literal)\n",
        "# #        |     |  └─ \"quickly\" (literal)\n",
        "# #        |     └─ \"running\" (metaphor)\n",
        "# #        └─ start token (ignore)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43aaf49",
      "metadata": {
        "id": "b43aaf49"
      },
      "source": [
        "## Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TF3EJkqXj0_j",
      "metadata": {
        "id": "TF3EJkqXj0_j"
      },
      "outputs": [],
      "source": [
        "df_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2U2MAKRyVJlY",
      "metadata": {
        "id": "2U2MAKRyVJlY"
      },
      "outputs": [],
      "source": [
        "# Split by documents to prevent leakage\n",
        "doc_ids_all = df_filtered[\"document_name\"].unique()\n",
        "\n",
        "# First split into train and temp (validation + test) document IDs\n",
        "train_ids, temp_ids = train_test_split(doc_ids_all, test_size=0.3, random_state=123) # e.g., 70% train, 30% temp\n",
        "\n",
        "# Split temp into validation and test document IDs\n",
        "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=123) # e.g., 15% validation, 15% test\n",
        "\n",
        "# Create sentence-level DataFrames for train, validation, and test using filtered document IDs\n",
        "train_df_all = df_filtered[df_filtered[\"document_name\"].isin(train_ids)].copy().reset_index(drop=True)\n",
        "val_df_all   = df_filtered[df_filtered[\"document_name\"].isin(val_ids)].copy().reset_index(drop=True)\n",
        "test_df_all  = df_filtered[df_filtered[\"document_name\"].isin(test_ids)].copy().reset_index(drop=True)\n",
        "\n",
        "print(f\"Train size (all sentences): {len(train_df_all)}\")\n",
        "print(f\"Val size (all sentences): {len(val_df_all)}\")\n",
        "print(f\"Test size (all sentences): {len(test_df_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Brn5mN9SCmIi",
      "metadata": {
        "id": "Brn5mN9SCmIi"
      },
      "outputs": [],
      "source": [
        "# count the number of each pos occurences in train_df_all\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "Counter([p for lst in train_df_all['pos'] for p in lst if pd.notna(p)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45400fe3",
      "metadata": {
        "id": "45400fe3"
      },
      "outputs": [],
      "source": [
        "def sample_balanced_pos(df, pos_categories_to_balance, random_state=42):\n",
        "    \"\"\"\n",
        "    Samples sentences to achieve a roughly equal number of metaphorical tokens\n",
        "    for the specified POS categories, based on the count of the most underrepresented category.\n",
        "    \"\"\"\n",
        "    # First, count the occurrences of metaphorical tokens for each specified POS category\n",
        "    pos_counts_in_metaphors = {pos: 0 for pos in pos_categories_to_balance}\n",
        "    for index, row in df.iterrows():\n",
        "        metaphorical_indices = [i for i, label in enumerate(row['labels']) if label == 1]\n",
        "        if not metaphorical_indices:\n",
        "            continue\n",
        "\n",
        "        sentence_pos = row['pos']\n",
        "        metaphorical_pos = [sentence_pos[i] for i in metaphorical_indices if i < len(sentence_pos)]\n",
        "\n",
        "        for pos in metaphorical_pos:\n",
        "            if pos in pos_counts_in_metaphors:\n",
        "                pos_counts_in_metaphors[pos] += 1\n",
        "\n",
        "    # Determine the count of the most underrepresented POS category\n",
        "    min_pos_count = min(pos_counts_in_metaphors.values())\n",
        "    print(f\"Target samples per balanced POS category: {min_pos_count}\")\n",
        "\n",
        "    sampled_indices = []\n",
        "    current_pos_counts = {pos: 0 for pos in pos_categories_to_balance}\n",
        "\n",
        "    # Iterate through the DataFrame again to sample\n",
        "    for index, row in df.iterrows():\n",
        "        metaphorical_indices = [i for i, label in enumerate(row['labels']) if label == 1]\n",
        "        if not metaphorical_indices:\n",
        "            continue\n",
        "\n",
        "        sentence_pos = row['pos']\n",
        "        metaphorical_pos = [sentence_pos[i] for i in metaphorical_indices if i < len(sentence_pos)]\n",
        "\n",
        "        # Check if adding this sentence helps reach the target for any of the specified POS\n",
        "        add_sentence = False\n",
        "        for pos in metaphorical_pos:\n",
        "            if pos in current_pos_counts and current_pos_counts[pos] < min_pos_count:\n",
        "                add_sentence = True\n",
        "                break\n",
        "\n",
        "        if add_sentence:\n",
        "            sampled_indices.append(index)\n",
        "            # Update counts for the specified POS tags in the sentence\n",
        "            for pos in metaphorical_pos:\n",
        "                if pos in current_pos_counts:\n",
        "                    current_pos_counts[pos] += 1\n",
        "\n",
        "    # Create a new DataFrame with the sampled sentences\n",
        "    sampled_df = df.loc[sampled_indices].reset_index(drop=True)\n",
        "    return sampled_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yvJb0Pba_ah6",
      "metadata": {
        "id": "yvJb0Pba_ah6"
      },
      "source": [
        "This code defines the sample_balanced_pos function, which is designed to create a more balanced training dataset by sampling sentences. Its goal is to achieve a roughly equal representation of metaphorical tokens for specific Parts-of-Speech (POS) categories, particularly useful in cases of class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the POS categories to balance\n",
        "pos_categories_to_balance = ['noun', 'verb', 'adj', 'adv', 'nan']\n",
        "\n",
        "# Sample the training data with balanced POS for specified categories\n",
        "train_df_balanced_pos = sample_balanced_pos(train_df_all, pos_categories_to_balance, random_state=42)"
      ],
      "metadata": {
        "id": "nH-oZIugty9M"
      },
      "id": "nH-oZIugty9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa470483",
      "metadata": {
        "id": "fa470483"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# For validation and test sets, we can sample a fixed number of sentences for consistency\n",
        "# val_df_sampled = val_df_all.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "# test_df_sampled = test_df_all.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "train_df_sampled = train_df_all.sample(n=3000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(f\"Train size (balanced POS): {len(train_df_sampled)} sentences\")\n",
        "# print(f\"Train size (balanced POS): {len(train_df_balanced_pos)} sentences\")\n",
        "print(f\"Val size: {len(val_df_all)}\")\n",
        "print(f\"Test size: {len(test_df_all)}\")\n",
        "\n",
        "# Create the datasets from the sampled dataframes\n",
        "train_dataset_sampled = MetaphorSentenceDataset(train_df_sampled, tokenizer, max_len=32)\n",
        "# train_dataset_balanced_pos = MetaphorSentenceDataset(train_df_balanced_pos, tokenizer, max_len=32)\n",
        "val_dataset = MetaphorSentenceDataset(val_df_all, tokenizer, max_len=32)\n",
        "test_dataset = MetaphorSentenceDataset(test_df_all, tokenizer, max_len=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330b7057",
      "metadata": {
        "id": "330b7057"
      },
      "outputs": [],
      "source": [
        "# Recalculate counts for the balanced dataframe\n",
        "balanced_pos_counts = {pos: 0 for pos in pos_categories_to_balance}\n",
        "\n",
        "for index, row in train_df_balanced_pos.iterrows():\n",
        "    for i, label in enumerate(row['labels']):\n",
        "        if label == 1:\n",
        "            pos = row['pos'][i]\n",
        "            if pos in balanced_pos_counts:\n",
        "                balanced_pos_counts[pos] += 1\n",
        "\n",
        "print(\"Metaphorical POS token counts in train_df_balanced_pos:\")\n",
        "for pos, count in balanced_pos_counts.items():\n",
        "    print(f\"{pos.capitalize()}: {count} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "upsKObyoCWg-",
      "metadata": {
        "id": "upsKObyoCWg-"
      },
      "source": [
        "Since 'verb' naturally has more metaphorical occurrences in the dataset, even after sampling enough sentences to bring 'adv' up to 1009, 'verb' might still have a higher count (2296). This is because a single sampled sentence can contain multiple metaphorical tokens, contributing to the counts of several POS categories simultaneously. The function adds sentences until the min_pos_count is met for all target categories; it doesn't then remove sentences to reduce the counts of categories that ended up with more.\n",
        "\n",
        "This approach helps to mitigate severe underrepresentation without necessarily forcing all categories to the exact same frequency, which might involve discarding too much data from naturally more frequent categories. The goal is to ensure the model has sufficient examples of each type of metaphorical POS, even if some types still appear more often than others within the balanced set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ecbc1d7",
      "metadata": {
        "id": "9ecbc1d7"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "print(\"torch version:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"cuda device count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"current device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\n",
        "print(\"num threads:\", torch.get_num_threads())\n",
        "print(\"TOKENIZERS_PARALLELISM:\", os.environ.get(\"TOKENIZERS_PARALLELISM\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e24dac",
      "metadata": {
        "id": "25e24dac"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "sample_texts = [list(x) for x in train_df_balanced_pos['words'].tolist()[:1000]]  # ensure list of lists of str\n",
        "t0 = time.time()\n",
        "_ = tokenizer(sample_texts, is_split_into_words=True, padding='max_length', truncation=True, max_length=32)\n",
        "print(\"1000-sample batch tokenization time:\", time.time()-t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RMeq_e0ldof6",
      "metadata": {
        "id": "RMeq_e0ldof6"
      },
      "source": [
        "## Calculating class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28b1020",
      "metadata": {
        "id": "d28b1020"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights for imbalanced data\n",
        "train_labels_flat = [label for labels in train_df_all[\"labels\"] for label in labels]\n",
        "unique_classes = np.unique(train_labels_flat)\n",
        "class_weights = compute_class_weight('balanced', classes=unique_classes, y=train_labels_flat)\n",
        "\n",
        "print(f\"Class distribution in training data:\")\n",
        "print(f\"Literal (0): {train_labels_flat.count(0)} tokens ({100*train_labels_flat.count(0)/len(train_labels_flat):.1f}%)\")\n",
        "print(f\"Metaphor (1): {train_labels_flat.count(1)} tokens ({100*train_labels_flat.count(1)/len(train_labels_flat):.1f}%)\")\n",
        "print(f\"Enhanced class weights: Literal={class_weights[0]:.2f}, Metaphor={class_weights[1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5b4e48",
      "metadata": {
        "id": "6d5b4e48"
      },
      "source": [
        "### Custom Trainer with Weighted Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb7995d",
      "metadata": {
        "id": "bbb7995d"
      },
      "outputs": [],
      "source": [
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = torch.FloatTensor(class_weights)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        #Enhanced compute_loss with weighted cross entropy for class imbalance\n",
        "        expected_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "        model_inputs = {key: inputs[key] for key in expected_keys if key in inputs}\n",
        "\n",
        "        labels = model_inputs.get(\"labels\") # Get labels separately as they are used in loss calculation\n",
        "\n",
        "        # Pass expected inputs to the model\n",
        "        outputs = model(**model_inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Move class weights to correct device\n",
        "        device = logits.device\n",
        "        class_weights_device = self.class_weights.to(device)\n",
        "\n",
        "        # Create weighted cross entropy loss\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_device, ignore_index=-100)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7579356",
      "metadata": {
        "id": "d7579356"
      },
      "outputs": [],
      "source": [
        "# Enhanced compute metrics with detailed class-specific metrics\n",
        "def compute_metrics_enhanced(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.argmax(axis=-1)\n",
        "\n",
        "    # Remove ignored index (-100 values)\n",
        "    predictions = predictions[labels != -100].flatten()\n",
        "    labels = labels[labels != -100].flatten()\n",
        "\n",
        "    # Calculate metrics for both classes\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None, zero_division=0)\n",
        "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted', zero_division=0)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': weighted_f1,\n",
        "        'precision': weighted_precision,\n",
        "        'recall': weighted_recall,\n",
        "        'literal_f1': f1[0] if len(f1) > 0 else 0.0,\n",
        "        'metaphor_f1': f1[1] if len(f1) > 1 else 0.0,\n",
        "        'literal_precision': precision[0] if len(precision) > 0 else 0.0,\n",
        "        'metaphor_precision': precision[1] if len(precision) > 1 else 0.0,\n",
        "        'literal_recall': recall[0] if len(recall) > 0 else 0.0,\n",
        "        'metaphor_recall': recall[1] if len(recall) > 1 else 0.0,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc047b2a",
      "metadata": {
        "id": "cc047b2a"
      },
      "source": [
        "## Optimizing Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774f6814",
      "metadata": {
        "id": "774f6814"
      },
      "outputs": [],
      "source": [
        "# def quick_evaluate_balance(weights, train_size=1000, val_size=400):\n",
        "#     # Quickly evaluate class weights on small samples\n",
        "\n",
        "#     # Tiny training and validation datasets\n",
        "#     tiny_train_dataset = MetaphorSentenceDataset(\n",
        "#         train_df_all.sample(train_size, random_state=42), tokenizer, max_len=32\n",
        "#     )\n",
        "#     tiny_val_dataset = MetaphorSentenceDataset(\n",
        "#         val_df_all.sample(val_size, random_state=42), tokenizer, max_len=32\n",
        "#     )\n",
        "\n",
        "#     # Ultra-fast training\n",
        "#     quick_args = TrainingArguments(\n",
        "#         output_dir=\"./temp_model\",\n",
        "#         eval_strategy=\"no\",\n",
        "#         save_strategy=\"no\",\n",
        "#         learning_rate=1e-4,\n",
        "#         per_device_train_batch_size=32,\n",
        "#         num_train_epochs=1,\n",
        "#         logging_steps=999999,\n",
        "#         warmup_steps=0,\n",
        "#         fp16=True,\n",
        "#         remove_unused_columns=False\n",
        "#     )\n",
        "\n",
        "#     model = RobertaForTokenClassification.from_pretrained(\"distilroberta-base\", num_labels=2)\n",
        "#     trainer = WeightedTrainer(\n",
        "#         class_weights=weights,\n",
        "#         model=model,\n",
        "#         args=quick_args,\n",
        "#         train_dataset=tiny_train_dataset,\n",
        "#         tokenizer=tokenizer,\n",
        "#     )\n",
        "\n",
        "#     trainer.train()\n",
        "\n",
        "#     # Evaluate\n",
        "#     preds = trainer.predict(tiny_val_dataset)\n",
        "#     y_pred = preds.predictions.argmax(axis=-1)\n",
        "#     mask = preds.label_ids != -100\n",
        "#     y_true, y_pred_clean = preds.label_ids[mask], y_pred[mask]\n",
        "\n",
        "#     # Return metaphor F1\n",
        "#     f1_scores = precision_recall_fscore_support(y_true, y_pred_clean, average=None, zero_division=0)[2]\n",
        "#     return f1_scores[1] if len(f1_scores) > 1 else 0\n",
        "\n",
        "\n",
        "# # Test different class weight multipliers\n",
        "# balance_results = {}\n",
        "# for m in [0.3, 0.4, 0.5, 0.6]:\n",
        "#     balance_results[m] = quick_evaluate_balance([class_weights[0], class_weights[1] * m])\n",
        "#     print(f\"Multiplier {m}: Metaphor F1 = {balance_results[m]:.3f}\")\n",
        "\n",
        "# best_multiplier = max(balance_results, key=balance_results.get)\n",
        "# final_weights = [class_weights[0], class_weights[1] * best_multiplier]\n",
        "# print(f\"Best balance multiplier: {best_multiplier}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0abyUOXIU0kb",
      "metadata": {
        "id": "0abyUOXIU0kb"
      },
      "outputs": [],
      "source": [
        "final_weights = [class_weights[0], class_weights[1] * 0.4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j2dhUsBDtJoE",
      "metadata": {
        "id": "j2dhUsBDtJoE"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import XLMRobertaForTokenClassification\n",
        "\n",
        "# Create model and training configuration\n",
        "model_balanced = XLMRobertaForTokenClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2)\n",
        "\n",
        "training_args_bal_fast = TrainingArguments(\n",
        "    output_dir=\"./xlm-roberta-base\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    dataloader_num_workers=4,\n",
        "    fp16=True,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize weighted trainer\n",
        "trainer_balanced = WeightedTrainer(\n",
        "    class_weights=final_weights,\n",
        "    model=model_balanced,\n",
        "    args=training_args_bal_fast,\n",
        "    train_dataset=train_dataset_sampled,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics_enhanced,\n",
        ")\n",
        "\n",
        "# Train the balanced model\n",
        "print(\"Training class-balanced xlm-roberta-base model with optimized weights\")\n",
        "trainer_balanced.train()\n",
        "\n",
        "print(\"Class-balanced training completed with enhanced metaphor detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I_niRg3Sdjet",
      "metadata": {
        "id": "I_niRg3Sdjet"
      },
      "source": [
        "1636a7c4bf2237ac398dd011cd9d5f7804e65863"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f62ca8",
      "metadata": {
        "id": "f8f62ca8"
      },
      "source": [
        "### Qualitative evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d3cdc76",
      "metadata": {
        "id": "1d3cdc76"
      },
      "source": [
        "## Evaluating the Final Model on Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e0c0cd",
      "metadata": {
        "id": "00e0c0cd"
      },
      "outputs": [],
      "source": [
        "preds_out = trainer_balanced.predict(test_dataset)\n",
        "logits = preds_out.predictions\n",
        "y_pred = logits.argmax(axis=-1)\n",
        "y_true = preds_out.label_ids\n",
        "\n",
        "rows = []\n",
        "n_samples = y_pred.shape[0]\n",
        "\n",
        "for i in range(n_samples):\n",
        "    word_ids = test_dataset.word_ids_list[i]\n",
        "    pos_seq = test_dataset.simple_pos_list[i]\n",
        "    sentence_words = test_dataset.df.loc[i, \"words\"]\n",
        "    input_ids = test_dataset.encodings[\"input_ids\"][i].tolist()\n",
        "\n",
        "    seq_len = min(len(word_ids), y_pred.shape[1], len(input_ids), len(y_true[i]))\n",
        "    for j in range(seq_len):\n",
        "        if y_true[i][j] == -100:\n",
        "            continue\n",
        "\n",
        "        wid = word_ids[j]\n",
        "        if wid is None or not (0 <= wid < len(sentence_words)):\n",
        "            continue\n",
        "\n",
        "        rows.append({\n",
        "            \"original_word\": sentence_words[wid],\n",
        "            \"pos\": pos_seq[j],\n",
        "            \"true_label\": \"Metaphor\" if int(y_true[i][j]) == 1 else \"Literal\",\n",
        "            \"pred_label\": \"Metaphor\" if int(y_pred[i][j]) == 1 else \"Literal\",\n",
        "            \"sentence\": \" \".join(sentence_words)\n",
        "        })\n",
        "\n",
        "df_tokens = pd.DataFrame(rows)\n",
        "\n",
        "# Set pandas to display the full content of each column (no truncation)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"\\n--- True Positives (Metaphor, Predicted Metaphor) ---\")\n",
        "true_positives = df_tokens[(df_tokens['true_label'] == 'Metaphor') & (df_tokens['pred_label'] == 'Metaphor')]\n",
        "if not true_positives.empty:\n",
        "    print(true_positives.sample(min(4, len(true_positives)) ).to_string())\n",
        "else:\n",
        "    print(\"No True Positives found.\")\n",
        "\n",
        "print(\"\\n--- False Positives (Literal, Predicted Metaphor) ---\")\n",
        "false_positives = df_tokens[(df_tokens['true_label'] == 'Literal') & (df_tokens['pred_label'] == 'Metaphor')]\n",
        "if not false_positives.empty:\n",
        "    print(false_positives.sample(min(4, len(false_positives)) ).to_string())\n",
        "else:\n",
        "    print(\"No False Positives found.\")\n",
        "\n",
        "print(\"\\n--- False Negatives (Metaphor, Predicted Literal) ---\")\n",
        "false_negatives = df_tokens[(df_tokens['true_label'] == 'Metaphor') & (df_tokens['pred_label'] == 'Literal')]\n",
        "if not false_negatives.empty:\n",
        "    print(false_negatives.sample(min(4, len(false_negatives)) ).to_string())\n",
        "else:\n",
        "    print(\"No False Negatives found.\")\n",
        "\n",
        "print(\"\\n--- True Negatives (Literal, Predicted Literal) ---\")\n",
        "true_negatives = df_tokens[(df_tokens['true_label'] == 'Literal') & (df_tokens['pred_label'] == 'Literal')]\n",
        "if not true_negatives.empty:\n",
        "    print(true_negatives.sample(min(4, len(true_negatives)) ).to_string())\n",
        "else:\n",
        "    print(\"No True Negatives found.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display y_pred and y_true\n",
        "print(y_pred)\n",
        "print(y_true)"
      ],
      "metadata": {
        "id": "hrgqjic3w_N4"
      },
      "id": "hrgqjic3w_N4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80627cb",
      "metadata": {
        "id": "c80627cb"
      },
      "outputs": [],
      "source": [
        "# --- Get predictions ---\n",
        "preds_out = trainer_balanced.predict(test_dataset)\n",
        "logits = preds_out.predictions\n",
        "y_pred = logits.argmax(axis=-1)\n",
        "y_true = preds_out.label_ids\n",
        "mask = y_true != -100\n",
        "\n",
        "# Clean arrays (only real tokens)\n",
        "y_true_clean = y_true[mask].flatten()\n",
        "y_pred_clean = y_pred[mask].flatten()\n",
        "\n",
        "print(\"Overall Performance (Class-Balanced Model):\")\n",
        "print(classification_report(\n",
        "    y_true_clean, y_pred_clean,\n",
        "    target_names=['Literal', 'Metaphor'],\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# --- Align POS tags with non-ignored tokens ---\n",
        "aligned_pos_clean = []\n",
        "for i, mask_row in enumerate(mask):\n",
        "    pos_tags = test_dataset.simple_pos_list[i]\n",
        "\n",
        "    aligned_pos_clean.extend([\n",
        "        pos_tags[j] for j, m in enumerate(mask_row) if m\n",
        "    ])\n",
        "\n",
        "# Unique POS tags in your data\n",
        "unique_pos = sorted(set(aligned_pos_clean))\n",
        "\n",
        "print(\"\\nPOS categories found in dataset:\", unique_pos)\n",
        "\n",
        "# --- Classification report for each POS ---\n",
        "for pos_tag in unique_pos:\n",
        "    pos_mask = np.array([p == pos_tag for p in aligned_pos_clean])\n",
        "\n",
        "    if pos_mask.sum() == 0:\n",
        "        continue\n",
        "\n",
        "    y_true_pos = y_true_clean[pos_mask]\n",
        "    y_pred_pos = y_pred_clean[pos_mask]\n",
        "\n",
        "    print(f\"\\n=== POS: {pos_tag} ===\")\n",
        "    print(classification_report(\n",
        "        y_true_pos, y_pred_pos,\n",
        "        target_names=['Literal', 'Metaphor'],\n",
        "        zero_division=0\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support\n",
        "\n",
        "# y_true_clean, y_pred_clean already computed on test set\n",
        "print(\"Detailed per-class report (Literal vs Metaphor):\")\n",
        "print(classification_report(\n",
        "    y_true_clean,\n",
        "    y_pred_clean,\n",
        "    target_names=['Literal', 'Metaphor'],\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "macro_f1 = f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0)\n",
        "micro_f1 = f1_score(y_true_clean, y_pred_clean, average='micro', zero_division=0)\n",
        "\n",
        "print(f\"Macro F1 (test): {macro_f1:.4f}\")\n",
        "print(f\"Micro F1 (test): {micro_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "AFAYT2peyeZ4"
      },
      "id": "AFAYT2peyeZ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05578700",
      "metadata": {
        "id": "05578700"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predictions\n",
        "preds_out = trainer_balanced.predict(test_dataset)\n",
        "logits = preds_out.predictions\n",
        "y_pred = logits.argmax(axis=-1)\n",
        "y_true = preds_out.label_ids\n",
        "mask = y_true != -100\n",
        "\n",
        "y_true_clean = y_true[mask].flatten()\n",
        "y_pred_clean = y_pred[mask].flatten()\n",
        "\n",
        "# Align metaphor-type labels\n",
        "aligned_met_clean = []\n",
        "for i, mask_row in enumerate(mask):\n",
        "    met_tags = test_dataset.metaphor_type_list[i]\n",
        "    aligned_met_clean.extend([met_tags[j] for j, m in enumerate(mask_row) if m])\n",
        "\n",
        "# Metaphor categories\n",
        "categories = [\"Direct\", \"Indirect\", \"Double\", \"Personification\"]\n",
        "\n",
        "for cat in categories:\n",
        "\n",
        "    # Select literal + this category\n",
        "    slice_mask = np.array([\n",
        "        (m == cat) or (m == \"literal\")\n",
        "        for m in aligned_met_clean\n",
        "    ])\n",
        "\n",
        "    y_true_sub = y_true_clean[slice_mask]\n",
        "    y_pred_sub = y_pred_clean[slice_mask]\n",
        "\n",
        "    # Skip if empty slice\n",
        "    if len(y_true_sub) == 0:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n=== Evaluation: {cat} vs Literal ===\")\n",
        "\n",
        "    print(classification_report(\n",
        "        y_true_sub,\n",
        "        y_pred_sub,\n",
        "        target_names=['Literal', cat],\n",
        "        zero_division=0\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type with meaningful performance:\n",
        "\n",
        "Indirect (mrw/met): moderate-high F1 (0.72) and good recall (0.82). This is the only subtype with enough support and decent metrics to draw strong conclusions.\n",
        "\n",
        "Types with unstable or degenerate metrics (data-scarce):\n",
        "\n",
        "Direct (mrw/lit), Double (mrw/met/double), Personification (mrw/met/PP) all have very small support (17, 18, 83), leading to:\n",
        "\n",
        "Extremely low precision.\n",
        "\n",
        "F1 scores near 0 despite sometimes high recall.\n",
        "\n",
        "The low number of instances for these types makes type-specific metrics unreliable; they are reported for completeness but should be interpreted with caution.\n"
      ],
      "metadata": {
        "id": "55kO_dHvzY1y"
      },
      "id": "55kO_dHvzY1y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a31df6",
      "metadata": {
        "id": "49a31df6"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true_clean, y_pred_clean)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Literal', 'Metaphor'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Final Model with All Data\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b9396d",
      "metadata": {
        "id": "f9b9396d"
      },
      "outputs": [],
      "source": [
        "# # F1 Score by POS Category\n",
        "# Prepare data for plotting\n",
        "pos_labels = ['noun', 'verb', 'adj', 'adv','nan']\n",
        "f1_scores = []\n",
        "for pos in pos_labels:\n",
        "    comparison_mask = np.array([p == pos or p == 'na' for p in aligned_pos_clean])\n",
        "    if comparison_mask.sum() > 0:\n",
        "        y_true_sub = y_true_clean[comparison_mask]\n",
        "        y_pred_sub = y_pred_clean[comparison_mask]\n",
        "        f1 = precision_recall_fscore_support(y_true_sub, y_pred_sub, average=None, zero_division=0)[2]\n",
        "        f1_scores.append(f1[1] if len(f1) > 1 else 0.0)\n",
        "    else:\n",
        "        f1_scores.append(0.0)\n",
        "df_f1 = pd.DataFrame({'POS': pos_labels, 'F1 Score': f1_scores})\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='POS', y='F1 Score', data=df_f1, palette='mako')\n",
        "plt.title('F1 Score by POS Category (Final Model on a Test Set)')\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('POS Category')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "how to handle pos and met_type imbalance"
      ],
      "metadata": {
        "id": "QeR4rAgHQk-a"
      },
      "id": "QeR4rAgHQk-a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## extension to russian\n"
      ],
      "metadata": {
        "id": "ufYJGRvvztEo"
      },
      "id": "ufYJGRvvztEo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "“We fine‑tune a multilingual encoder (XLM‑RoBERTa) on English VUAMC for token‑level metaphor detection, and then reuse it as a frozen encoder for cross‑lingual sentence‑level metaphor identification in English and Russian SVO/Adj‑N constructions.”"
      ],
      "metadata": {
        "id": "V9bw4sNiUcma"
      },
      "id": "V9bw4sNiUcma"
    },
    {
      "cell_type": "code",
      "source": [
        "# List ALL sheets in the Excel file\n",
        "excel_file = pd.ExcelFile('Datasets_ACL2014.xlsx')\n",
        "print(\"Available sheets:\")\n",
        "for sheet in excel_file.sheet_names:\n",
        "    print(f\"  - {sheet}\")"
      ],
      "metadata": {
        "id": "XFzNVRUePt1E"
      },
      "id": "XFzNVRUePt1E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_acl2014_sheets(file_path):\n",
        "    \"\"\"\n",
        "    Load EXACT sheets from your Datasets_ACL2014.xlsx\n",
        "    - LIT_* → label=0, MET_* → label=1\n",
        "    - AN = AdjN, SVO = SVO\n",
        "    \"\"\"\n",
        "    sheet_configs = [\n",
        "        # (sheet_name, lang, construction)\n",
        "        ('LIT_SVO_EN', 'EN', 'SVO'),\n",
        "        ('MET_SVO_EN', 'EN', 'SVO'),\n",
        "        ('LIT_SVO_RU', 'RU', 'SVO'),\n",
        "        ('MET_SVO_RU', 'RU', 'SVO'),\n",
        "        ('LIT_AN_EN',  'EN', 'AdjN'),\n",
        "        ('MET_AN_EN',  'EN', 'AdjN'),\n",
        "        ('LIT_AN_RU',  'RU', 'AdjN'),\n",
        "        ('MET_AN_RU',  'RU', 'AdjN'),\n",
        "    ]\n",
        "\n",
        "    all_rows = []\n",
        "\n",
        "    for sheet_name, lang, constr in sheet_configs:\n",
        "        print(f\"Loading {sheet_name}...\")\n",
        "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "        # Label: 1 if MET_*, else 0\n",
        "        label = 1 if sheet_name.startswith('MET_') else 0\n",
        "\n",
        "        # Build phrase based on construction\n",
        "        if constr == 'SVO':\n",
        "            # SVO sheets have subject, verb, object\n",
        "            phrase = (df['subject'].fillna('') + ' ' +\n",
        "                     df['verb'].fillna('') + ' ' +\n",
        "                     df['object'].fillna('')).str.strip()\n",
        "        else:  # AdjN\n",
        "            # AN sheets have adj, noun\n",
        "            phrase = (df['adj'].fillna('') + ' ' +\n",
        "                     df['noun'].fillna('')).str.strip()\n",
        "\n",
        "        # Full input: \"phrase | sentence\"\n",
        "        text = (phrase + ' | ' + df['sentence'].fillna('')).str.strip()\n",
        "\n",
        "        tmp_df = pd.DataFrame({\n",
        "            'text': text,\n",
        "            'label': label,\n",
        "            'lang': lang,\n",
        "            'construction': constr\n",
        "        })\n",
        "\n",
        "        # Filter out empty/short texts\n",
        "        tmp_df = tmp_df[tmp_df['text'].str.len() > 10]\n",
        "        all_rows.append(tmp_df)\n",
        "        print(f\"  → {len(tmp_df)} examples (label={label})\")\n",
        "\n",
        "    acl_df = pd.concat(all_rows, ignore_index=True)\n",
        "    return acl_df\n",
        "\n",
        "# Load it!\n",
        "acl_df = load_acl2014_sheets('Datasets_ACL2014.xlsx')\n",
        "print(f\"\\n=== FINAL DATASET ===\")\n",
        "print(f\"Total: {len(acl_df)} examples\")\n",
        "print(\"\\nDistribution:\")\n",
        "print(acl_df.groupby(['lang', 'construction', 'label']).size().unstack(fill_value=0))\n",
        "\n",
        "print(\"\\nSample rows:\")\n",
        "print(acl_df.head())\n"
      ],
      "metadata": {
        "id": "6w6KRQalz7Iz"
      },
      "id": "6w6KRQalz7Iz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acl_df.head()"
      ],
      "metadata": {
        "id": "3s4j6fbJJMN-"
      },
      "id": "3s4j6fbJJMN-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embeddings_from_token_model(texts, model, tokenizer, max_length=64,\n",
        "                                             device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                padding=True\n",
        "            )\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            # Call the encoder inside the classifier\n",
        "            # For XLMRobertaForTokenClassification, this is usually .roberta\n",
        "            encoder_outputs = model.roberta(**inputs)\n",
        "            cls_emb = encoder_outputs.last_hidden_state[:, 0, :]  # [CLS]\n",
        "            embeddings.append(cls_emb.cpu().numpy()[0])\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "print(\"Extracting embeddings from model_balanced encoder...\")\n",
        "acl_embeddings = get_sentence_embeddings_from_token_model(\n",
        "    acl_df['text'].tolist(),\n",
        "    model_balanced,\n",
        "    tokenizer  # the tokenizer you used for VUAMC\n",
        ")\n",
        "acl_df['embedding'] = list(acl_embeddings)\n",
        "print(\"✅ Embeddings extracted!\")\n"
      ],
      "metadata": {
        "id": "iO-zJaFWGk19"
      },
      "id": "iO-zJaFWGk19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acl_df.head()"
      ],
      "metadata": {
        "id": "tKdemCURT2ez"
      },
      "id": "tKdemCURT2ez",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_transfer(lang, construction):\n",
        "    \"\"\"Train linear head and evaluate on one language/construction split\"\"\"\n",
        "    subset = acl_df[(acl_df['lang'] == lang) & (acl_df['construction'] == construction)]\n",
        "\n",
        "    if len(subset) < 20:\n",
        "        print(f\"⚠️  Skipping {lang}-{construction}: too few examples ({len(subset)})\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n=== {lang.upper()}-{construction}: {len(subset)} examples ===\")\n",
        "\n",
        "    X = np.stack(subset['embedding'].values)\n",
        "    y = subset['label'].values\n",
        "\n",
        "    # 80/20 split (train linear head / test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train linear head (1 minute)\n",
        "    clf = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    y_pred = clf.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(classification_report(y_test, y_pred, target_names=['Literal', 'Metaphor']))\n",
        "    return {\n",
        "        'lang': lang,\n",
        "        'construction': construction,\n",
        "        'n_train': len(X_train),\n",
        "        'n_test': len(X_test),\n",
        "        'f1': f1,\n",
        "        'support_metaphor': sum(y_test)\n",
        "    }\n",
        "\n",
        "# Run full evaluation matrix\n",
        "results = []\n",
        "for lang in ['EN', 'RU']:\n",
        "    for constr in ['SVO', 'AdjN']:\n",
        "        result = evaluate_transfer(lang, constr)\n",
        "        if result:\n",
        "            results.append(result)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== VUAMC → SVO/AdjN TRANSFER SUMMARY ===\")\n",
        "print(results_df.pivot(index='construction', columns='lang', values='f1').round(3))\n"
      ],
      "metadata": {
        "id": "9XHHe0LBHuwq"
      },
      "id": "9XHHe0LBHuwq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A transfer experiment:\n",
        "\n",
        "Encoder: XLM‑RoBERTa fine‑tuned on VUAMC for token‑level metaphor detection.\n",
        "\n",
        "Task: sentence‑level classification of whether an SVO or Adj–N construction is metaphorical, in English and Russian.\n",
        "\n",
        "Classifier: logistic regression on frozen [CLS] embeddings.\n",
        "\n",
        "Key claims supported by the numbers:\n",
        "\n",
        "“The VUAMC‑trained multilingual encoder supports accurate SVO and Adj–N metaphor identification in English (F1 0.83–0.90).”\n",
        "\n",
        "“The same encoder transfers well to Russian, achieving F1 between 0.89 and 0.93 on small SVO and Adj–N datasets without re‑training the encoder.”"
      ],
      "metadata": {
        "id": "upgyHPkVvCEn"
      },
      "id": "upgyHPkVvCEn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a multilingual encoder (XLM-RoBERTa) fine-tuned for token-level\n",
        "metaphor detection on English VUAMC. Despite no Russian training data,\n",
        "the learned representations transfer to Russian SVO/AdjN classification\n",
        "(F1=0.89–0.92), demonstrating cross-lingual generalization."
      ],
      "metadata": {
        "id": "CZJ6g1oVwMyK"
      },
      "id": "CZJ6g1oVwMyK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe higher F1 scores on the ACL2014 SVO/AdjN task (0.83–0.93)\n",
        "compared to VUAMC token-level detection (~0.76). This reflects three factors:\n",
        "\n",
        "1. **Task granularity**: Sentence-level classification of whole SVO/AdjN\n",
        "   constructions is intrinsically easier than token-level labeling [Gong et al., 2018].\n",
        "\n",
        "2. **Data balance**: ACL2014 sheets are perfectly balanced (50% metaphor),\n",
        "   while VUAMC has ~10–15% metaphor tokens, making F1 more sensitive to\n",
        "   false positives [VUA Shared Task, 2018].\n",
        "\n",
        "3. **Example prototypicality**: ACL2014 contains clear prototypical metaphors\n",
        "   vs literals, while VUAMC reflects real corpus diversity with edge cases.\n",
        "\n",
        "The high ACL2014 performance confirms that VUAMC representations capture\n",
        "general metaphor signals, though token-level detection remains the harder task.\n"
      ],
      "metadata": {
        "id": "4j9GvlT0xVe0"
      },
      "id": "4j9GvlT0xVe0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model explainability"
      ],
      "metadata": {
        "id": "2uDIvIvZoXSE"
      },
      "id": "2uDIvIvZoXSE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention visualization (does it focus on metaphorical tokens?)"
      ],
      "metadata": {
        "id": "Qlt2IExcokb2"
      },
      "id": "Qlt2IExcokb2"
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_metaphor_attention(model, tokenizer, test_dataset, num_examples=3):\n",
        "    \"\"\"\n",
        "    BULLETPROOF VERSION: handles all tensor shapes correctly.\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    metaphor_indices = [i for i in range(len(test_dataset))\n",
        "                       if np.sum(np.array(test_dataset.df.iloc[i]['labels'])) > 0]\n",
        "    random_indices = np.random.choice(metaphor_indices, num_examples, replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(num_examples, 1, figsize=(16, 4.5*num_examples))\n",
        "    if num_examples == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for plot_idx, dataset_idx in enumerate(random_indices):\n",
        "        row = test_dataset.df.iloc[dataset_idx]\n",
        "        words = row['words']\n",
        "        gold_labels = np.array(row['labels'])\n",
        "        met_words = [words[i] for i,l in enumerate(gold_labels) if l==1]\n",
        "\n",
        "        print(f\"Plot {plot_idx}: idx={dataset_idx}, metaphors={met_words}\")\n",
        "\n",
        "        example = test_dataset[dataset_idx]\n",
        "        input_ids = example['input_ids'].unsqueeze(0).to(device)\n",
        "        attention_mask = example['attention_mask'].unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.roberta(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                output_attentions=True\n",
        "            )\n",
        "            attention = encoder_outputs.attentions[-1][0, 0].cpu().numpy()\n",
        "\n",
        "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu())\n",
        "\n",
        "        # FIXED: Proper attention_mask extraction\n",
        "        # Get the 1D attention mask for the first example in the batch\n",
        "        content_mask = attention_mask[0].cpu().numpy().astype(bool)\n",
        "\n",
        "        # Slice attention to content only\n",
        "        attention_content = attention[content_mask][:, content_mask]\n",
        "        tokens_content = np.array(tokens)[content_mask] # Convert tokens to numpy array for boolean indexing\n",
        "\n",
        "        print(f\"  Tokens shown: {len(tokens_content)} (of {len(tokens)} total)\")\n",
        "\n",
        "        # Plot\n",
        "        sns.heatmap(attention_content,\n",
        "                   xticklabels=tokens_content,\n",
        "                   yticklabels=tokens_content,\n",
        "                   cmap='Blues', ax=axes[plot_idx],\n",
        "                   cbar_kws={'label': 'Attention'})\n",
        "\n",
        "        # Metaphor highlighting (simplified for content region)\n",
        "        axes[plot_idx].set_title(f\"Idx {dataset_idx}: {len(met_words)} metaphors\")\n",
        "        axes[plot_idx].tick_params(axis='x', rotation=90)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"✅ Clean heatmaps - no padding!\")\n",
        "\n",
        "# Run it!\n",
        "visualize_metaphor_attention(model_balanced, tokenizer, test_dataset, num_examples=3)\n"
      ],
      "metadata": {
        "id": "-EeGNd1p2EzL"
      },
      "id": "-EeGNd1p2EzL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BertViz (run once)\n",
        "!pip install bertviz\n",
        "\n",
        "from bertviz import head_view, model_view\n",
        "import torch\n",
        "import numpy as np # Ensure numpy is imported\n"
      ],
      "metadata": {
        "id": "I3ybKGHd2Hz7"
      },
      "id": "I3ybKGHd2Hz7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rows = \"what's looking\"\n",
        "Columns = \"what it's looking at\"\n",
        "Color = \"how much attention\" (darker = more attention)\n"
      ],
      "metadata": {
        "id": "A6YcYJw-CX71"
      },
      "id": "A6YcYJw-CX71"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def bertviz_metaphor_example(model, tokenizer, test_dataset, example_idx):\n",
        "    \"\"\"\n",
        "    BertViz visualization for your model_balanced + test_dataset.\n",
        "    Takes a specific example_idx as input.\n",
        "    \"\"\"\n",
        "    # Get example\n",
        "    example = test_dataset[example_idx]\n",
        "    row = test_dataset.df.iloc[example_idx]\n",
        "\n",
        "    print(f\"Using example {example_idx} from the test_dataset with {len(row['words'])} words\")\n",
        "\n",
        "    # Original words and labels\n",
        "    words = [str(w) for w in row['words']] # Explicitly convert to list of strings\n",
        "    gold_labels = np.array(row['labels'])\n",
        "    met_positions = np.where(gold_labels == 1)[0]\n",
        "\n",
        "    print(f\"Words: {' '.join(words)}\")\n",
        "    print(f\"Metaphor tokens: {[words[i] for i in met_positions]}\")\n",
        "\n",
        "    # Tokenize for BertViz\n",
        "    inputs = tokenizer(\n",
        "        words,\n",
        "        return_tensors='pt',\n",
        "        is_split_into_words=True,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "    # Get attentions from your model\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device # Ensure model is on correct device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()} # Move inputs to device\n",
        "    with torch.no_grad():\n",
        "        # Use encoder part\n",
        "        encoder_outputs = model.roberta(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            output_attentions=True\n",
        "        )\n",
        "\n",
        "    # BertViz expects specific format\n",
        "    attentions = encoder_outputs.attentions\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "    print(\"\\n🧠 BertViz attention visualization:\")\n",
        "    print(\"(Interactive: click layers/heads to zoom)\")\n",
        "\n",
        "    # Head view (best for metaphors)\n",
        "    head_view(attentions, tokens)\n",
        "\n",
        "    return example_idx\n"
      ],
      "metadata": {
        "id": "F_0BiMV0P1VN"
      },
      "id": "F_0BiMV0P1VN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running bertviz\n",
        "example_idx = bertviz_metaphor_example(model_balanced, tokenizer, test_dataset, example_idx=4)\n"
      ],
      "metadata": {
        "id": "lm-2O6HDKXG4"
      },
      "id": "lm-2O6HDKXG4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "wFwIVgPjQvnZ"
      },
      "id": "wFwIVgPjQvnZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def neuron_metaphor_analysis(model, tokenizer, test_dataset):\n",
        "    \"\"\"\n",
        "    Integrated Gradients: which input tokens most affect metaphor neurons.\n",
        "    \"\"\"\n",
        "    ig = IntegratedGradients(model.roberta)\n",
        "\n",
        "    example_idx = 0  # First with metaphors\n",
        "    while example_idx < len(test_dataset):\n",
        "        row = test_dataset.df.iloc[example_idx]\n",
        "        if np.sum(np.array(row['labels'])) > 0:\n",
        "            break\n",
        "        example_idx += 1\n",
        "\n",
        "    example = test_dataset[example_idx]\n",
        "    words = test_dataset.df.iloc[example_idx]['words']\n",
        "\n",
        "    inputs = tokenizer(words, return_tensors='pt', is_split_into_words=True)\n",
        "\n",
        "    # Attribute input to layer 8 [CLS] neuron 42 (example)\n",
        "    attributions = ig.attribute(inputs['input_ids'],\n",
        "                               target=42,  # Neuron index\n",
        "                               return_convergence_delta=True)\n",
        "\n",
        "    # Plot token importance\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.bar(range(len(words)), attributions[0].sum(0).squeeze().cpu().numpy())\n",
        "    plt.xticks(range(len(words)), words, rotation=90)\n",
        "    plt.title(\"Neuron 42 attribution to input tokens\")\n",
        "    plt.axhline(0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_0zqc2_jRlCY"
      },
      "id": "_0zqc2_jRlCY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run neuron analysis\n",
        "neuron_metaphor_analysis(model_balanced, tokenizer, test_dataset)"
      ],
      "metadata": {
        "id": "BjpvrD7GRZ1j"
      },
      "id": "BjpvrD7GRZ1j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d482b24d"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}